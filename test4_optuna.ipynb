{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# --- 1. DATA PREPARATION ---\n",
    "\n",
    "# Let's assume 'df' is your DataFrame and 'loan_paid_back' is the target\n",
    "# X = df.drop('loan_paid_back', axis=1)\n",
    "# y = df['loan_paid_back']\n",
    "\n",
    "# Identify your categorical features by NAME\n",
    "# Note: combine your Nominal and Ordinal lists for CatBoost\n",
    "cat_features_names = ORDINAL_COLS + NOMINAL_COLS\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create CatBoost Pools (Optimized internal data structure)\n",
    "# This is much faster for Optuna to reuse than passing raw DataFrames every time\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=cat_features_names)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features_names)\n",
    "\n",
    "# --- 2. DEFINE THE OBJECTIVE FUNCTION ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna will run this function many times with different parameters.\n",
    "    It returns the score (accuracy/AUC) to maximize.\n",
    "    \"\"\"\n",
    "    \n",
    "    # A. Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'iterations': 1000,                        # Fixed high number, use early stopping\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10), # CatBoost prefers 6-10\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1, 10),\n",
    "        'border_count': 254,                       # Max splits for numerical features (default 254)\n",
    "        \n",
    "        # Hardcoded parameters\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',                      # Or 'Accuracy'\n",
    "        'verbose': False,                          # Keep output clean\n",
    "        'task_type': 'CPU',                        # Change to 'GPU' if available\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "\n",
    "    # B. Train the model with these parameters\n",
    "    model = CatBoostClassifier(**param)\n",
    "    \n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    \n",
    "    # C. Return the metric to optimize\n",
    "    # Since we set use_best_model=True, model.predict uses the best iteration\n",
    "    preds_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, preds_proba)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "# --- 3. RUN THE OPTIMIZATION ---\n",
    "\n",
    "print(\"Starting Optuna Optimization...\")\n",
    "study = optuna.create_study(direction='maximize') # We want to maximize AUC\n",
    "study.optimize(objective, n_trials=30) # Run 30 different experiments\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"BEST PARAMETERS FOUND:\")\n",
    "print(study.best_params)\n",
    "print(f\"BEST AUC: {study.best_value}\")\n",
    "\n",
    "# --- 4. TRAIN FINAL MODEL ---\n",
    "\n",
    "# Take the best parameters found by Optuna\n",
    "best_params = study.best_params\n",
    "\n",
    "# Add the fixed parameters back in (since they weren't in the 'best_params' dict)\n",
    "best_params['iterations'] = 2000 # Increase iterations for final robust model\n",
    "best_params['loss_function'] = 'Logloss'\n",
    "best_params['eval_metric'] = 'AUC'\n",
    "best_params['task_type'] = 'CPU'\n",
    "best_params['early_stopping_rounds'] = 100\n",
    "\n",
    "print(\"\\nTraining Final Model with Best Parameters...\")\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(\n",
    "    train_pool, \n",
    "    eval_set=test_pool, \n",
    "    use_best_model=True, \n",
    "    plot=True # Nice graph in Jupyter\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
