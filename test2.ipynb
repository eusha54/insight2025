{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d987817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53459, 12)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Rough\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loan_full = pd.read_csv('data/train.csv', index_col=0)\n",
    "test = pd.read_csv('data/test.csv', index_col=0)\n",
    "# submission = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "cols = loan_full.columns\n",
    "feats = cols[:-1]\n",
    "target = cols[-1]\n",
    "\n",
    "\n",
    "# taking sample of the data\n",
    "loan, loan_test = train_test_split(loan_full, stratify=loan_full[target], train_size=0.15, random_state=42)\n",
    "loan.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c490a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade_subgrade labeling\n",
    "grades = 'ABCDEFG'\n",
    "subgrades = [ch+str(i) for ch in grades for i in range(1,6)]\n",
    "grade_mapping = {\n",
    "    subgrade: i+1 for i, subgrade in enumerate(subgrades)\n",
    "}\n",
    "\n",
    "# education_level labeling\n",
    "education_mapping = {\n",
    "    'High School': 1,\n",
    "    'Other': 2,\n",
    "    \"Bachelor's\": 3,\n",
    "    \"Master's\": 4,\n",
    "    'PhD': 5\n",
    "}\n",
    "\n",
    "# one hot encoding pipeline\n",
    "ohe_pipeline = Pipeline(steps=[\n",
    "    (\"ohe\", OneHotEncoder(\n",
    "        drop=\"first\",\n",
    "        sparse_output=False,\n",
    "        handle_unknown=\"ignore\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# col lists\n",
    "ORDINAL_COLS = ['grade_subgrade', 'education_level']\n",
    "\n",
    "NOMINAL_COLS = ['gender', 'marital_status', 'employment_status', 'loan_purpose']\n",
    "\n",
    "NUMERICAL_COLS = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "834999a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def data_preprocess(data):\n",
    "    X = data[feats].copy()\n",
    "    y = data[target].apply(int).copy()\n",
    "\n",
    "\n",
    "    X['education_level'] = X['education_level'].map(education_mapping)\n",
    "    X['grade_subgrade'] = X['grade_subgrade'].map(grade_mapping)\n",
    "\n",
    "\n",
    "    X_ohe = ohe_pipeline.fit_transform(X[NOMINAL_COLS])\n",
    "    X_ohe_df = pd.DataFrame(X_ohe, columns=ohe_pipeline.get_feature_names_out(), index=X.index)\n",
    "\n",
    "    X = pd.concat([X.drop(columns=NOMINAL_COLS), X_ohe_df], axis=1)\n",
    "    return X,y\n",
    "\n",
    "X,y = data_preprocess(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "81a4a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(\n",
    "    n_neighbors=5\n",
    ")\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    max_depth=None, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=8, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "et_clf = ExtraTreesClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_clf = SVC(\n",
    "    kernel='rbf', \n",
    "    probability=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    n_estimators=1000, \n",
    "    max_depth=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    n_estimators=50, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbc_clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=500,\n",
    "    max_depth=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    depth=3,\n",
    "    learning_rate=0.1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "21dc082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 32058, number of negative: 8036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1343\n",
      "[LightGBM] [Info] Number of data points in the train set: 40094, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.799571 -> initscore=1.383615\n",
      "[LightGBM] [Info] Start training from score 1.383615\n",
      "0.9794482965032174\n",
      "0.9009352787130565\n"
     ]
    }
   ],
   "source": [
    "clf = lgbm_clf\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "train_y_pred = clf.predict(train_X)\n",
    "test_y_pred = clf.predict(test_X)\n",
    "\n",
    "print(accuracy_score(train_y, train_y_pred))\n",
    "print(accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85495f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gbc_clf\n",
    "    0.9048486057764255\n",
    "    0.904900860456416\n",
    "\n",
    "rf_clf\n",
    "    0.9027784705941039\n",
    "    0.903179947624392\n",
    "    0.9007255973692185\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fe7ecf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8995203623195582\n"
     ]
    }
   ],
   "source": [
    "X_full, y_full = data_preprocess(loan_test)\n",
    "y_full_pred = clf.predict(X_full)\n",
    "print(accuracy_score(y_full, y_full_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission file \n",
    "\n",
    "test[target] = None\n",
    "X_test_full, _ = data_preprocess(test)\n",
    "y_test_full_pred = clf.predict(X_test_full)\n",
    "\n",
    "submission_df = pd.DataFrame(y_test_full_pred, columns=[target], index=X_test_full.index)\n",
    "submission_df.to_csv(\"test_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8489d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
